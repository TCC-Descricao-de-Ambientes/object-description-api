<!DOCTYPE html>
<html lang="en">
<meta name="viewport" content="width=device-width, initial-scale=1">

<head>
  <nav class="navbar fixed-top navbar-dark bg-dark">
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
      aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <a class="navbar-brand">Menu</a> <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarNav">

      <ul class="navbar-nav">

        <li class="nav-item active">
          <a class="nav-link" href="/">Home <span class="sr-only">(current)</span></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="/objective">Objective</a>
        </li>
        <li class="nav-item">
          <a class="nav-link " href="/about">About us</a>
        </li>
      </ul>

    </div>
  </nav>
  <title>Objective</title>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

</head>

<body style="background-color: #343a40;">

  <div class="card bg-dark text-white">
    <img style="opacity: 0.2;" class="card-img" src="https://miro.medium.com/max/900/1*EYtn2YE7b6MTzMQyD2R3nA.jpeg"
      alt="Card image">
    <div class="card-img-overlay">
      <br>
      <br>
      <header style="text-align: left;">
        <h1>Objective - Abstract</h1>
      </header>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <div class="row">
        <div class="col-sm-12">
          <div class="card bg-light text-white">
            <div class="card-body">
              <h5 style="color: black; text-align: center;" class="card-title">Abstract</h5>
              <p style="color: black;">
                The field of Computer Vision was revolutionized with the introduction of Neural Networks, they enabled
                the creation of technologies such as facial recognition, detection and classification of objects and is
                responsible, in parts, for the growing advance of autonomous vehicles, among several other
                contributions. Despite the constant improvement in this field, we found out that there are not many
                technologies capable of textually describing scenes captured by photographic cameras, especially in
                systems with limited computational power. We propose a low computational processing application capable
                of generating a text describing which objects were identified and their qualitative direction in
                relation to the camera. To execute this work, we will use the SSD MobileNet which will be trained to
                identify objects in indoor environments, using the union of two datasets, NYU-Depth and COCO-Dataset.
                For the classification of its position in the scene, we will create an algorithm based on the concept of
                Qualitative Spatial Reasoning.
              </p>
            </div>
          </div>
        </div>
      </div>

    </div>
  </div>


  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
    crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
    integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
    crossorigin="anonymous"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
    integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
    crossorigin="anonymous"></script>

</body>

</html>